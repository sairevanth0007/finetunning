[
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 35.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 15.2% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.9% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.7% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.1% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.7% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.7% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 36.6% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.2% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.1% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 22.7% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.3% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.9% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 33.1% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 19.9% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 35.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.3% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 23.3% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.7% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.7% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 11.1% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 17.4% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 41.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.7% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 34.1% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 27.5% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.2% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 45.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 24.1% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 31.7% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 36.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 30.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.2% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.2% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 45.2% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.3% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.5% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 40.2% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 10.4% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 41.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 18.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 18.2% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 19.2% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.1% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 15.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 42.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 25.8% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 17.1% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 45.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 18.9% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 34.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 43.0% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 34.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.6% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 36.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.7% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 26.2% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 42.1% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.2% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 34.5% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 33.3% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.7% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 10.9% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 17.0% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 28.3% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.3% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 30.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 14.9% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 13.0% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.6% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 10.8% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 18.1% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 35.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 19.2% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 26.7% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 45.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.5% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.7% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 32.2% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 13.7% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 34.3% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 40.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 14.0% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.9% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 11.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.1% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 18.9% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 36.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.5% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 42.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 43.1% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 25.7% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 13.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 34.9% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 40.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 11.9% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.8% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.2% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.3% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 11.1% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 14.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 32.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 43.9% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.5% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 14.5% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.8% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 45.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.7% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 14.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.0% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 13.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.9% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 20.0% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 34.2% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.9% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 14.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.6% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.3% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 26.3% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 12.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 23.5% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.7% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 11.4% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 20.7% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 11.2% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 43.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 30.6% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 17.7% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 40.7% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.8% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.2% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 25.6% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 30.1% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.8% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 10.0% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.7% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 42.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 23.5% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 23.2% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 23.7% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 45.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 23.5% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 15.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 32.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.3% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 33.7% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 29.0% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 42.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 40.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 20.2% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.5% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 43.7% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 11.5% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 33.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.6% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 10.4% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 28.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 42.1% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 36.3% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 20.2% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.7% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.2% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 13.2% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 19.5% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 30.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 21.6% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 36.1% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 21.4% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 10.2% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 22.8% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.1% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 41.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 32.6% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.9% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 31.9% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.8% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 40.9% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 32.4% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 30.6% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 33.6% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 15.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 14.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.5% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 19.0% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 23.9% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 11.1% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 19.5% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 22.7% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 38.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 21.3% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 43.4% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 24.2% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.2% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 35.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 10.6% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.8% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.7% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 40.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 32.0% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 33.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.5% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 12.2% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.2% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.9% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.0% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.9% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 31.3% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.0% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 16.4% accuracy. Hyperparameters: lr=0.001, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.001, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 37.9% accuracy. Hyperparameters: lr=0.005, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.5% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.8% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.3% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 35.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.0% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 34.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 54.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 47.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 39.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.2% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 49.5% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.5% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.6% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 52.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 50.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.8% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.6% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.9% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.0% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 53.4% accuracy. Hyperparameters: lr=0.01, momentum=0.9, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.9, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 58.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 26.6% accuracy. Hyperparameters: lr=0.005, momentum=0.85, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.85, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 9.6% accuracy. Hyperparameters: lr=0.001, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.001, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 44.4% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 2048, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 61.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.7% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.6% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 51.2% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 2048, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 46.7% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=9,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 3072),\n            nn.ReLU(inplace=True),\n            nn.Linear(3072, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 9, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 3072, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 26.8% accuracy. Hyperparameters: lr=0.01, momentum=0.85, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 5, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.85, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.4% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 57.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 5, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 56.5% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=11,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 11, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 384, 'conv5_filters': 192, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 62.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.4",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 256, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.4}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 59.3% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(4096, 2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 256, 'conv4_filters': 256, 'conv5_filters': 192, 'fc1_neurons': 4096, 'fc2_neurons': 2048, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 60.0% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 64, kernel_size=7,\n                      stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 64\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 64, 'conv1_kernel': 7, 'conv1_stride': 3, 'conv2_filters': 256, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 48.9% accuracy. Hyperparameters: lr=0.005, momentum=0.95, dropout=0.6",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 96, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 96\n\n        layers += [\n            nn.Conv2d(in_channels, 128, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 128\n\n        layers += [\n            nn.Conv2d(in_channels, 440, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 440\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 3072),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(3072, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 96, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 128, 'conv2_kernel': 3, 'conv3_filters': 440, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 3072, 'fc2_neurons': 4096, 'lr': 0.005, 'momentum': 0.95, 'dropout': 0.6}\n"
  },
  {
    "input": "Generate a CNN for CIFAR-10 with approximately 55.1% accuracy. Hyperparameters: lr=0.01, momentum=0.95, dropout=0.5",
    "output": "import torch\nimport torch.nn as nn\n\n\ndef supported_hyperparameters():\n    return {'lr', 'momentum', 'dropout'}\n\n\nclass Net(nn.Module):\n    def train_setup(self, prm):\n        self.to(self.device)\n        self.criteria = (nn.CrossEntropyLoss().to(self.device),)\n        self.optimizer = torch.optim.SGD(\n            self.parameters(),\n            lr=prm['lr'],\n            momentum=prm['momentum']\n        )\n\n    def learn(self, train_data):\n        self.train()\n        for inputs, labels in train_data:\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self(inputs)\n            loss = self.criteria[0](outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.parameters(), 3)\n            self.optimizer.step()\n\n    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:\n        super().__init__()\n        self.device = device\n        layers = []\n        in_channels = in_shape[0]\n\n        layers += [\n            nn.Conv2d(in_channels, 32, kernel_size=7,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 32\n\n        layers += [\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 192\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        ]\n        in_channels = 384\n\n        layers += [\n            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        ]\n        in_channels = 256\n        self.features = nn.Sequential(*layers)\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n\n        dropout_p = prm['dropout']\n        classifier_input_features = in_channels * 6 * 6\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout_p),\n            nn.Linear(classifier_input_features, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_p),\n            nn.Linear(2048, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, out_shape[0]),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# --- Chromosome used to generate this model ---\n# Chromosome: {'conv1_filters': 32, 'conv1_kernel': 7, 'conv1_stride': 4, 'conv2_filters': 192, 'conv2_kernel': 3, 'conv3_filters': 384, 'conv4_filters': 384, 'conv5_filters': 256, 'fc1_neurons': 2048, 'fc2_neurons': 4096, 'lr': 0.01, 'momentum': 0.95, 'dropout': 0.5}\n"
  }
]